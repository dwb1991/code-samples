import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as dates
import sys
import numpy as np
from datetime import timedelta, datetime, date

def Generate_Step_1_CSV(df):
    
    """Input is a dataframe with 'Time','Message_Id','Sender','Recipients','Topic','Mode', and 'hour', 
        generated from Make_df()"""
    """Output is a .csv file with three columns: 'person', 'sent', 'received'"""
    #This counts how many times each name appears in the 'sent' column.
    sender_count=df.groupby('Sender')['Message_Id'].nunique().sort_values(ascending=False) #Sorted based on the number of emails sent (as instructed)
    
    #Generating the same for the received column is a little trickier, first all_recipients is 
    #generated by turning everything in received column into its own data frame.
    all_recipients=pd.DataFrame(df['Recipients'].str.split('|', expand=True).values.tolist()) 
    all_recipients['Message_Id']=df['Message_Id'] #Set the data frame's index as the Message ID to keep it in the same order.
    
    #Melt the DataFrame around the Message_Id column to generate a new DataFrame with each recipient mapped to the message ID.
    df_melt=pd.melt(all_recipients, col_level=0, id_vars=['Message_Id']) 
    df_melt['value'].replace('', np.nan, inplace=True)
    df_melt=df_melt.dropna() #Remove any null columns, as some are created when melting.
    
    #value_counts() counts the instances of each name in the melted recieved column, which defaults to 'value'.
    recipient_count=df_melt['value'].value_counts() 
    
    #Join sender_count and recipient_count, rename the columns to the ones indicated, and replace NAs with 0s for clarity.
    step_1_csv=sender_count.to_frame().join(recipient_count.to_frame()).reset_index()
    step_1_csv=step_1_csv.rename(index=str, columns={"Sender": "person", "Message_Id": "sent", "value": "received"})
    step_1_csv=step_1_csv.fillna(value=0)
    step_1_csv.to_csv('Step_1_Person_Sent_Recieved.csv', encoding='utf-8', index=False)
    print ("Step 1 Complete.")
    return step_1_csv


def Generate_Step_2_Heatmap(step_1_csv, freq = 'M', how_many_users=4, min_number_of_emails=1000):
    
    """Input is the csv from Generate_Step_1_CSV(), a frequency ('M' works best but 'W' is possible), how many users you want to display (between 1 and 4),
        and min_number_of_emails is how strictly you want to filter what constitutes a 'high volume sender."""
    """Output is a .png file with up to 4 heatmaps in quadrants."""
    
    sender_count=df.groupby('Sender')['Message_Id'].nunique().sort_values(ascending=False)#I wanted these scripts to be modular so I added this part again even though it appears in earlier scripts.
    High_volume_senders=step_1_csv.loc[step_1_csv['sent'] > min_number_of_emails]['person'] #Choose users who sent at least 1000 emails
    email_high_volume=sender_count.loc[sender_count.index.isin(High_volume_senders)]#Save a list of senders who have sent at least 1000 emails.   
    earliest = df['Time'].min() # Set the range of dates by taking min and max.
    latest = df['Time'].max()
    per = pd.period_range(earliest, latest, freq=freq) #to generate ticks on the range by freq
    heatmap=[] #initialize lists that will be appended to in a loop to generate plots for how_many_users
    df_unique=[]
    ax=[]
    fig = plt.figure(figsize=(40,20))
    if how_many_users <=4 and how_many_users > 0: #Users must be greater than 0 
        for i in (range(0, how_many_users)): #This for loop generates heatmaps in up to 4 quadrants in the .png
            heatmap.append(pd.DataFrame(np.zeros([len(per), 24]) , index=per)) #Initialize the heatmap by creating a matrix of 0s.
            df_unique.append(df[df['Sender']==email_high_volume.index[i]])#Add the dataframe from each high volume sender to a new dataframe in a list
            for period in per:
                if period in df.index:
                    #Generates the heatmap by taking the number of emails sent per hour using value_counts(). This allows for multiple heatmaps to be generated.
                    heatmap[i].ix[period] = df_unique[i].ix[[period]].hour.value_counts() 
            heatmap[i].fillna(0, inplace=True) #Replace NAs with 0s
            
            #A new quadrant for each iteration of the loop. The first quadrant in matplotlib corresponds to 221, the second 222, third 223, and fourth 224.
            ax.append(plt.subplot(i+221)) 
                
            x_axis = dates.date2num([p.start_time for p in per]) #Turns the dates into numeric for plotting
            time = [datetime(2000, 1, 1, h, 0, 0) for h in range(24)] #To generate y axis we need a datetime of 24 hours
            time.append(datetime(2000, 1, 2, 0, 0, 0)) #Another zero is needed
            y_axis = dates.date2num(time) #Converts this list to num
            
            plt.pcolor(x_axis, y_axis, heatmap[i].transpose().as_matrix(), cmap=plt.get_cmap('PuRd')) #Generate the plots, transposing the 0 based heatmap
            plt.suptitle("Heatmaps of Emails Sent Per Hour By Top Users")
            ax[i].set_title(email_high_volume.index[i].title())
            ax[i].xaxis.set_major_formatter(dates.DateFormatter('%b %Y'))
            ax[i].yaxis.set_major_formatter(dates.DateFormatter('%H:%M'))
            ax[i].set_yticks(time[::1])
            ax[i].set_xticks(x_axis[::6])
            ax[i].set_xlim([x_axis[0], x_axis[-1]])
            ax[i].set_ylim([time[0], time[-1]])
            cax = plt.axes([0.85, 0.1, 0.075, 0.8])
            plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9) 
            plt.colorbar(cax=cax) #This generates a color bar to help quantify the heatmap.
        plt.savefig('Step_2_Heatmap_Emails_Sent.png')        
    
    elif how_many_users <= 0:
        print ("ERROR: Number of users must be  greater than 0.")
        sys.exit(1)
    
    else: #if how_many_users > 4, this function will save multiple plots.
        for i in (range(0, how_many_users)): #This for loop generates heatmaps in up to 4 quadrants in the .png
            heatmap.append(pd.DataFrame(np.zeros([len(per), 24]) , index=per)) #Initialize the heatmap by creating a matrix of 0s.
            df_unique.append(df[df['Sender']==email_high_volume.index[i]])#Add the dataframe from each high volume sender to a new dataframe in a list
            for period in per:
                if period in df.index:
                    #Generates the heatmap by taking the number of emails sent per hour using value_counts(). This allows for multiple heatmaps to be generated.
                    heatmap[i].ix[period] = df_unique[i].ix[[period]].hour.value_counts() 
            heatmap[i].fillna(0, inplace=True) #Replace NAs with 0s
            
            #A new quadrant for each iteration of the loop. The first quadrant in matplotlib corresponds to 221, the second 222, third 223, and fourth 224.
            ax = plt.subplot(111)
                
            x_axis = dates.date2num([p.start_time for p in per]) #Turns the dates into numeric for plotting
            time = [datetime(2000, 1, 1, h, 0, 0) for h in range(24)] #To generate y axis we need a datetime of 24 hours
            time.append(datetime(2000, 1, 2, 0, 0, 0)) #Another zero is needed
            y_axis = dates.date2num(time) #Converts this list to num
            
            plt.pcolor(x_axis, y_axis, heatmap[i].transpose().as_matrix(), cmap=plt.get_cmap('PuRd')) #Generate the plots, transposing the 0 based heatmap
            plt.suptitle("Heatmaps of Emails Sent Per Hour By Top Users")
            ax.set_title(email_high_volume.index[i].title())
            ax.xaxis.set_major_formatter(dates.DateFormatter('%b %Y'))
            ax.yaxis.set_major_formatter(dates.DateFormatter('%H:%M'))
            ax.set_yticks(time[::1])
            ax.set_xticks(x_axis[::6])
            ax.set_xlim([x_axis[0], x_axis[-1]])
            ax.set_ylim([time[0], time[-1]])
            cax = plt.axes([0.85, 0.1, 0.075, 0.8])
            plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)
            plt.colorbar(cax=cax)#This generates a color bar to help quantify the heatmap.
            
            #Saves each fig as a separate .PNG. 
            #The directions called for a single .PNG,
            #so the default of the how_many_users is 4 to avoid saving multiple .PNGs, but the option is there.
            plt.savefig('Step_2_Heatmap_Emails_Sent_{i}.png'.format(i=i)) 
    print ("Step 2 Complete.")        
    return 

def Generate_Step_3_Graph(df, how_many_users = 4, freq='M', min_number_of_emails = 1000):
    
    """Input is a dataframe with 'Time','Message_Id','Sender','Recipients','Topic','Mode', and 'hour', generated from Make_df(), 
        how_many_users is the number of users you want to graph, 
        and min_number_of_emails is how strictly you want to filter what constitutes a 'high volume sender.'"""
    """Output is a graph showing the volume of emails received by each sender over the two year period, default 4."""
    #Begin by initializing the lists, as this function progressively builds the lists and plots the lines.
    all_recipients=[]
    df_unique=[]
    received=[]
    df_melt_list=[]
    ax=[]
    sender_count=df.groupby('Sender')['Message_Id'].nunique().sort_values(ascending=False) #I wanted these scripts to be modular so I added this part again even though it appears in earlier scripts.
    High_volume_senders=step_1_csv.loc[step_1_csv['sent'] > min_number_of_emails]['person']
    email_high_volume=sender_count.loc[sender_count.index.isin(High_volume_senders)]    
    fig=plt.figure()
    ax=fig.add_subplot(111) #Plot only one figure - new lines can be added on to the existing graph.
    for i in (range(0, how_many_users)):
        df_unique.append(df[df['Sender']==email_high_volume.index[i]]) #df_unique is the original df filtered to only include one user at a time
        all_recipients.append(pd.DataFrame(df_unique[i]['Recipients'].str.split('|', expand=True).values.tolist()))#Generate all_recipients again as in Generate_Step_1_CSV()
        df_unique[i]=df_unique[i].reset_index(drop=True)#adjust all_recipients so that it has the 'Message Id' column and has time as the index.
        all_recipients[i]['Message_Id']=df_unique[i]['Message_Id']
        all_recipients[i]['Time'] = df_unique[i]['Time']
        df_melt=pd.melt(all_recipients[i], col_level=0, id_vars=['Message_Id', 'Time']) #Melt the dataframe so that each recipient is mapped to its message Id and Time
        df_melt['value'].replace('', np.nan, inplace=True)
        df_melt=df_melt.dropna()
        df_melt = df_melt.set_index('Time', drop=False)
        df_melt.index = df_melt.index.to_period(freq) #sets the index as a period index so that the x axis of the graph is correct.
        df_melt_list.append(df_melt)
        fig = plt.figure(figsize=(20,20))
        received.append(df_melt_list[i].groupby(level=0)) #group by the index (period)
    
    for i in range(0, how_many_users):
        received[i]['value'].nunique().plot(label=email_high_volume.index[i].title()) #each line's label will be the sender
    plt.legend()
    plt.savefig('Step_3_Graph.png')
    print ("Step 3 Complete.")
    return 

def Make_df(input_file):
    """Input is the input csv"""
    """Outputs a DataFrame with 'Time','Message_Id','Sender','Recipients','Topic','Mode', and 'hour', used for later scripts"""
    df = pd.read_csv(input_file, header = None, names = ['Time','Message_Id','Sender','Recipients','Topic','Mode'])
    df['Time'] = pd.to_datetime(df['Time'], unit='ms') #convert the time from milliseconds to a timestamp.
    df['hour'] = df['Time'].dt.hour #extract the hours from the timestamp
    return df

if __name__ == "__main__":
	input_file = sys.argv[1]
	df = Make_df(input_file)
	step_1_csv=Generate_Step_1_CSV(df)
	df = df.set_index('Time', drop=False) #Set Time as the index
	df.index = df.index.to_period('M')
	Generate_Step_2_Heatmap(step_1_csv, how_many_users=4, freq = 'M', min_number_of_emails = 1000) 
	"""Interestingly, these heatmaps show a spike in activity at around October 2001, the month that the Enron scandal broke. 
	Except for Chris Germany, who appears to have wisely gone on vacation around that time. 
	"Notes" appears to be an automated system that was activated at around the time of the scandal."""
	Generate_Step_3_Graph(df, how_many_users = 4, min_number_of_emails = 1000)
	"""The same pattern as the heatmap appears in this graph as well. There is a frantic spike in activity at around October 2001. 
	Sentiment analysis on these emails would be very interesting as perhaps it could detect a scandal before it breaks.
	I imagine employee morale was rather low leading up to the scandal breaking."""
